{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wgpB7rU7rrk4BnoapdXtGyFmepqlRw6K",
      "authorship_tag": "ABX9TyNaiX7yjvMNrvF30w9SKmsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharani1999/Word-embedding-techniques/blob/master/Code_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTPPDaIkL-DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gensim\n",
        "from gensim import corpora, models, similarities\n",
        "from gensim.models import Word2Vec, TfidfModel, LsiModel\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.fasttext import FastText\n",
        "#pip install glove_python"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4XGZScCdZgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "75cec894-2eff-444b-9c52-988e6f9c8dbd"
      },
      "source": [
        "!pip install glove_python\n",
        "from glove import Corpus, Glove# creating a corpus object"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glove_python in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslXGch8IZgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_module(name, location, output_location, dict_location, max_seq_length=100):\n",
        "  dataset1 = pd.read_csv(location)\n",
        "  dataset = dataset1.iloc[0:1000,:]\n",
        "\n",
        "  if name == 'word2vec':\n",
        "    data_corpus, users_total = data_word2vec(dataset,max_seq_length)\n",
        "  elif name == 'doc2vec':\n",
        "    data_corpus, users_total = data_doc2vec(dataset,max_seq_length)\n",
        "  elif name == 'lsi':\n",
        "    data_corpus, users_total = data_lsi(dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'tfidf':\n",
        "    data_corpus, users_total = data_lsi(dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'glove':\n",
        "    data_corpus, users_total = data_word2vec(dataset,max_seq_length)\n",
        "  #elif name == 'fasttext':\n",
        "   # data_corpus, users_total = data_word2vec(dataset,max_seq_length)\n",
        "  #data_corpus.save('/content/drive/My Drive/Movielensdata/ml25m/data_corpus')\n",
        "  #print(data_corpus)\n",
        "  save_object(obj=data_corpus, filename=output_location)\n",
        "  #return data_corpus, users_total\n",
        "\n",
        "def data_word2vec(dataset,max_seq_length):\n",
        "  dataset.sort_values(by=['userId','timestamp'],inplace=True)\n",
        "  user_total = len(dataset['userId'].unique())\n",
        "  \n",
        "  #Selecting the most recent movies rated by each user and padding if necessary\n",
        "  movie_list = []\n",
        "  for i in range(user_total):\n",
        "    list1 = []\n",
        "    list1 = dataset.loc[dataset['userId'] ==(i+1),['movieId']]['movieId'].tolist()\n",
        "    if len(list1)>max_seq_length:\n",
        "      list1 = list1[(len(list1)-max_seq_length):]\n",
        "    elif len(list1)<max_seq_length:\n",
        "      list1 = list1+[0 for j in range((max_seq_length-len(list1)))]\n",
        "      #for j in range((max_seq_length-len(list1))):\n",
        "       # list1.append(0)\n",
        "    movie_list.append(list1)\n",
        "  \n",
        "  #Selecting the most recent ratings rated by each user and padding if necessary\n",
        "  rating_list =[]\n",
        "  for i in range(user_total):\n",
        "    list2 = []\n",
        "    list2 = dataset.loc[dataset['userId'] ==(i+1),['rating']]['rating'].tolist()\n",
        "    if len(list2)>max_seq_length:\n",
        "      list2 = list2[(len(list2)-max_seq_length):]\n",
        "    elif len(list2)<max_seq_length:\n",
        "      list2 = list2+[0 for j in range((max_seq_length-len(list2)))]\n",
        "      #for j in range((max_seq_length-len(list2))):\n",
        "       # list2.append(0)\n",
        "    rating_list.append(list2)\n",
        "  \n",
        "  #Creating user_id level transpose matrices\n",
        "  movies_transpose = pd.DataFrame(data=movie_list,index=[i+1 for i in range(user_total)])\n",
        "  movies_transpose.index.names = ['userId']\n",
        "  #print(movies_transpose)\n",
        "\n",
        "  ratings_transpose = pd.DataFrame(data=rating_list,index=[i+1 for i in range(user_total)])\n",
        "  ratings_transpose.index.names = ['userId']\n",
        "  #print(ratings_transpose)\n",
        "\n",
        "  # Select features from original dataset to form a new dataframe \n",
        "  df1 = movies_transpose.iloc[:]# For each row, combine all the columns into one column\n",
        "  df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)# Store them in a pandas dataframe\n",
        "  df_clean = pd.DataFrame({'clean': df2})# Create the list of list format of the custom corpus for gensim modeling \n",
        "  sent = [row.split(',') for row in df_clean['clean']]\n",
        "\n",
        "  return sent, user_total\n",
        "\n",
        "def data_doc2vec(dataset,max_seq_length):\n",
        "  Sent, user_total = data_word2vec(dataset,max_seq_length)\n",
        "  tagged_data = []\n",
        "  tags = []\n",
        "  \n",
        "  for i in range(user_total):\n",
        "    tagged_data = tagged_data + [TaggedDocument(words=Sent[i], tags=[str(i)])]\n",
        "\n",
        "  return tagged_data, user_total\n",
        "\n",
        "def data_lsi(dataset,max_seq_length,dict_loc):\n",
        "  Sent, user_total = data_word2vec(dataset,max_seq_length)\n",
        "  dictionary = corpora.Dictionary(Sent)\n",
        "  #print(dictionary.token2id)\n",
        "  corpus = [dictionary.doc2bow(text) for text in Sent]\n",
        "  dictionary.save(dict_loc)\n",
        "  #corpus = np.array([[(id, freq) for id, freq in cp] for cp in corp])\n",
        "  #corpus = gensim.matutils.Dense2Corpus(np.array(Sent),documents_columns=False)\n",
        "\n",
        "  return corpus, user_total"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nrx8P2P32kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_object(obj, filename):\n",
        "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
        "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_object(filename):\n",
        "    with open(filename, 'rb') as input:\n",
        "        pickle_object = pickle.load(input)\n",
        "    return  pickle_object"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kJytoDNK3E0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedding_model(name,Data_location,model_save_location, vector_dims=10,Sg=1,size_window=3,topics=10,mini_count=1,num_workers=3,max_num_epochs = 100,alpha = 0.025,min_alpha=0.00025,dm=1):\n",
        "  Data = load_object(Data_location)\n",
        "  #print(Data)\n",
        "  if name == 'word2vec':\n",
        "    word2vec(input_data=Data, save_loc=model_save_location, vec_dims=vector_dims, SG=Sg, size_of_window=size_window, minimum_count=mini_count, no_workers=num_workers)\n",
        "    #voc = model1.wv\n",
        "    #words = list(model1.wv.vocab)\n",
        "    #vectors = model1[model1.wv.vocab]\n",
        "  elif name == 'doc2vec':\n",
        "    doc2vec(input_data=Data, save_loc=model_save_location, vec_dims=vector_dims, alpha_=alpha, size_of_window=size_window, no_workers=num_workers, max_epochs=max_num_epochs,min_alpha_=min_alpha, minimum_count=mini_count, dms=dm)\n",
        "  elif name == 'lsi':\n",
        "    lsi(input_data=Data, save_loc=model_save_location, total_topics=topics)\n",
        "  elif name == 'tfidf':\n",
        "    tfidf(input_data=Data,save_loc=model_save_location)\n",
        "  elif name == 'glove':\n",
        "    glove_model(input_data=Data, vec_dims=vector_dims, size_of_window=size_window, save_loc=model_save_location, num_epochs=max_num_epochs, alpha_=0.05, num_threads=4)\n",
        "  #elif name == 'fasttext':\n",
        "   # fast_text(input_data=Data, save_loc=model_save_location, vec_dims=vector_dims, SG=Sg, size_of_window=size_window, minimum_count=mini_count, no_workers=num_workers, alpha_=0.025)\n",
        "\n",
        "def word2vec(input_data,save_loc,vec_dims,SG,size_of_window,minimum_count,no_workers):\n",
        "  model = Word2Vec(input_data,min_count=minimum_count,size= vec_dims,workers=no_workers, window =size_of_window, sg = SG)\n",
        "  model.save(save_loc)\n",
        "\n",
        "def doc2vec(input_data,save_loc,vec_dims,alpha_,size_of_window,min_alpha_,minimum_count,dms,no_workers,max_epochs):\n",
        "  model = Doc2Vec(size=vec_dims,\n",
        "                alpha=alpha_, \n",
        "                min_alpha=min_alpha_,\n",
        "                window = size_of_window,\n",
        "                min_count=minimum_count,\n",
        "                dm =dms)\n",
        "  model.build_vocab(input_data)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    #print('iteration {0}'.format(epoch))\n",
        "    model.train(input_data, total_examples=model.corpus_count, epochs=model.iter)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "  model.save(save_loc)\n",
        "\n",
        "def lsi(input_data,save_loc,total_topics):\n",
        "  model = models.LsiModel(corpus=input_data, num_topics=total_topics)\n",
        "  index = similarities.MatrixSimilarity(model[input_data])\n",
        "  lsi_data = model[input_data]\n",
        "  lsi_topics = model.print_topics()\n",
        "  #for topic in lsi_topics:\n",
        "    #print(topic)\n",
        "  model.save(save_loc)\n",
        "\n",
        "def tfidf(input_data,save_loc):\n",
        "  model = models.TfidfModel(corpus=input_data)\n",
        "  tfidf_data = model[input_data]\n",
        "\n",
        "  tfidf_token= np.zeros((len(tfidf_data), 350), dtype=np.float64)\n",
        "  tfidf_vals= np.zeros((len(tfidf_data), 350), dtype=np.float64)\n",
        " \n",
        "  for i in range(len(input_data)):\n",
        "    for k in range(len(list(tfidf_data)[i])):\n",
        "      tfidf_token[i][k]=(list(tfidf_data))[i][k][0]\n",
        "      tfidf_vals[i][k]=(list(tfidf_data))[i][k][1]\n",
        "  tfidf_list=list(tfidf_data)\n",
        "  #print(list(tfidf_data))\n",
        "  model.save(save_loc)\n",
        "\n",
        "def glove_model(input_data,vec_dims,size_of_window,save_loc,alpha_=0.05,num_epochs=30, num_threads=4):\n",
        "  #importing the glove library\n",
        "  corpus = Corpus() #training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "  corpus.fit(input_data, window=size_of_window)#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "  #We can set the learning rate as it uses Gradient Descent and number of components\n",
        "  glove = Glove(no_components=vec_dims, learning_rate=alpha_) \n",
        "  glove.fit(corpus.matrix, epochs=num_epochs, no_threads=4, verbose=True)\n",
        "  glove.add_dictionary(corpus.dictionary)\n",
        "  glove.save(save_loc)\n",
        "\n",
        "def fast_text(input_data,save_loc,vec_dims,SG,size_of_window,minimum_count,no_workers,alpha_=0.025):\n",
        "  model = FastText(min_count=minimum_count, alpha=alpha_, size= vec_dims, workers=no_workers, window =size_of_window)\n",
        "  model.build_vocab(input_data)\n",
        "  model.train(input_data, epochs=model.epochs, total_examples=model.corpus_count, total_words=model.corpus_total_words)\n",
        "  model.save(save_loc)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXlM6wLvQVIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scoring_module(name,model_loc,data,dict_loc):\n",
        "  if name == 'word2vec':\n",
        "    scores_list = score_word2vec(model_location=model_loc,input_data=data)\n",
        "  elif name == 'doc2vec':\n",
        "    scores_list = score_doc2vec(model_location=model_loc,input_data=data)\n",
        "  elif name == 'lsi':\n",
        "    scores_list = score_lsi(model_location=model_loc,input_data=data, dict_location=dict_loc)\n",
        "  elif name == 'tfidf':\n",
        "    scores_list = score_tfidf(model_location=model_loc,input_data=data, dict_location=dict_loc)\n",
        "  elif name == 'glove':\n",
        "    scores_list = score_glove(model_location=model_loc, input_data=data)\n",
        "  #elif name == 'fasttext':\n",
        "   # scores_list = score_fasttext(model_location=model_loc, input_data=data)\n",
        "  \n",
        "  return scores_list\n",
        "\n",
        "def score_word2vec(model_location,input_data):\n",
        "  model = Word2Vec.load(model_location)\n",
        "  scored_data = [model.wv[text] for text in input_data]\n",
        "  return scored_data\n",
        "\n",
        "def score_doc2vec(model_location,input_data):\n",
        "  model = Doc2Vec.load(model_location)\n",
        "  scored_data = [model.infer_vector(text) for text in input_data]\n",
        "  return scored_data\n",
        "\n",
        "def score_glove(model_location,input_data):\n",
        "  model = Glove.load(model_location)\n",
        "  scored_data = [model.word_vectors[model.dictionary[text]] for doc in input_data for text in doc]\n",
        "  #model.word_vectors[]\n",
        "  return scored_data\n",
        "\n",
        "def score_fasttext(model_location, input_data):\n",
        "  model = FastText(model_location)\n",
        "  scored_data = [model[text] for text in input_data]\n",
        "  return scored_data\n",
        "\n",
        "def score_lsi(model_location, input_data, dict_location):\n",
        "  model = LsiModel.load(model_location)\n",
        "  dictionary = corpora.Dictionary.load(dict_location)\n",
        "  scored_data = [model[dictionary.doc2bow(text)] for text in input_data]\n",
        "  return scored_data\n",
        "\n",
        "def score_tfidf(model_location, input_data, dict_location):\n",
        "  model = TfidfModel.load(model_location)\n",
        "  dictionary = corpora.Dictionary.load(dict_location)\n",
        "  scored_data = [model[dictionary.doc2bow(text)] for text in input_data]\n",
        "  return scored_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTON8_HeWKAV",
        "colab_type": "text"
      },
      "source": [
        "1) Name can be 'word2vec' or 'doc2vec' or 'lsi' or 'tfidf' or 'glove'.\n",
        "\n",
        "2) location is the path to input .csv file\n",
        "\n",
        "3) output_location is the path to save the processed data\n",
        "\n",
        "4) dict_location is the path to dictionary of LSI or TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajnRU9EfWhmP",
        "colab_type": "text"
      },
      "source": [
        "Change name, output_location for all models and dict_location for LSI and TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXdIQWmIGFOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "56946464-4dea-41de-955a-0b1ed69dddb6"
      },
      "source": [
        "data_module(name='word2vec',max_seq_length=100,location='/content/drive/My Drive/Movielensdata/ml25m/ratings.csv',output_location='/content/drive/My Drive/Movielensdata/ml25m/word2vec/data', dict_location='/content/drive/My Drive/Movielensdata/ml25m/lsi/dict')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaH5acqZYYI5",
        "colab_type": "text"
      },
      "source": [
        "Change name, Data_location and model_save_location for all models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iWoBWvRZwSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c77491e8-361a-4d4f-d1bc-8c5a5d3ae68f"
      },
      "source": [
        "embedding_model(name='word2vec',Data_location='/content/drive/My Drive/Movielensdata/ml25m/word2vec/data',model_save_location='/content/drive/My Drive/Movielensdata/ml25m/word2vec/w2v', vector_dims=10,Sg=1,size_window=3,topics=10,mini_count=1,num_workers=3,max_num_epochs = 10,alpha = 0.025,min_alpha=0.00025,dm=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WqzalHzc_lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scoring_input = [['899', '2161', '3949', '5878', '1175', '1237', '8154', '2843', '7365', '4422', '6016'],['1080', '3114', '3671', '2791', '1288', '1', '541', '2692', '7323', '8014', '6370', '4703', '5147']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vuSkxUwYf8J",
        "colab_type": "text"
      },
      "source": [
        "Change name, model_loc or all models and dict_loc for LSI and TF-IDF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry_oK4hcUcJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e9d0301c-b7d4-43ca-b7a9-3cc1abbaa37e"
      },
      "source": [
        "scored_list = scoring_module(name='word2vec', model_loc='/content/drive/My Drive/Movielensdata/ml25m/word2vec/w2v', data=scoring_input, dict_loc='/content/drive/My Drive/Movielensdata/ml25m/lsi/dict')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEHVPbZmaO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(scored_list[0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io4aqWLneCm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6b0bf1f-adcd-4f45-aa2e-fbd4067af7d6"
      },
      "source": [
        "print(scored_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[-0.04933006,  0.04133808, -0.04917735, -0.02006493, -0.04104522,\n",
            "         0.04374732,  0.04872967, -0.03336456, -0.00900195, -0.00565758],\n",
            "       [ 0.02511616, -0.04690189, -0.0229129 ,  0.00749706,  0.01298854,\n",
            "        -0.00767219,  0.02231734,  0.04114292,  0.00963719,  0.00451497],\n",
            "       [ 0.0446034 , -0.00638184,  0.01471467, -0.02314907,  0.00109761,\n",
            "        -0.03158027, -0.0307956 , -0.00399324,  0.02939923,  0.04343036],\n",
            "       [-0.01658672, -0.0318711 , -0.03179268, -0.00474806,  0.00295703,\n",
            "         0.01878951, -0.0005147 , -0.04795032, -0.01931167, -0.02296629],\n",
            "       [ 0.03595273, -0.04801391, -0.01320856, -0.02013416, -0.04749941,\n",
            "        -0.02759434,  0.02296375,  0.03000727,  0.02082018, -0.04409176],\n",
            "       [-0.02858855,  0.01934585, -0.01760966,  0.00831606, -0.01414228,\n",
            "         0.03060887, -0.02829752, -0.04952022,  0.03919851, -0.01542335],\n",
            "       [-0.04349007, -0.04446159,  0.02109938, -0.04250612, -0.04958392,\n",
            "        -0.04135284, -0.01030751,  0.04441076, -0.00260472,  0.02278729],\n",
            "       [ 0.03278779, -0.02580579, -0.00828448,  0.04979252,  0.04576629,\n",
            "         0.04532895, -0.01130488,  0.0009818 ,  0.04196787, -0.0133985 ],\n",
            "       [-0.01769287,  0.008774  , -0.0132192 ,  0.02784608,  0.03275806,\n",
            "        -0.02960888,  0.01642403,  0.03406471, -0.02223901, -0.04021887],\n",
            "       [-0.00839345,  0.01447099, -0.04614387, -0.0076403 , -0.00237188,\n",
            "         0.01534565, -0.04865465,  0.0337046 , -0.02297491,  0.01675462],\n",
            "       [ 0.02355604,  0.04684929, -0.01281135,  0.04578239,  0.00303545,\n",
            "        -0.03493583, -0.02024876,  0.0056456 ,  0.03791123, -0.03621859]],\n",
            "      dtype=float32), array([[ 9.3446084e-04,  4.6805803e-02, -3.1969965e-02,  1.6608849e-02,\n",
            "        -2.9723175e-02, -6.5991050e-03,  2.7557798e-02,  2.7289351e-02,\n",
            "         3.6049318e-03,  1.8212439e-02],\n",
            "       [-2.8935917e-02, -3.7121832e-02,  4.4668756e-02,  1.3009710e-02,\n",
            "         3.9470576e-02, -1.9113459e-02, -3.5779323e-02,  4.8414893e-02,\n",
            "        -2.9096052e-02,  2.4623772e-02],\n",
            "       [ 9.2605613e-03,  3.5599954e-02, -5.8261720e-03,  2.6103983e-02,\n",
            "         1.3695185e-02, -3.0223669e-03, -4.7603961e-02, -1.6067341e-02,\n",
            "         4.4164862e-02,  4.8221949e-02],\n",
            "       [-2.7120914e-02,  2.8876590e-02,  9.7137494e-03,  2.3873863e-03,\n",
            "         2.0835429e-02, -2.1818164e-03, -3.9548919e-02, -1.8353457e-02,\n",
            "        -8.7651927e-03,  2.4618939e-02],\n",
            "       [ 1.1149999e-02, -3.5136491e-02, -2.1023046e-02,  2.3399889e-02,\n",
            "        -1.3444050e-02,  7.4372547e-05,  2.8824836e-02, -2.7969791e-02,\n",
            "        -6.1231665e-03, -1.4291984e-02],\n",
            "       [-2.8708123e-02,  7.1807597e-03, -4.8072722e-02,  2.7976217e-02,\n",
            "        -4.5070626e-02, -2.2833353e-02, -4.3583792e-02,  4.5202147e-02,\n",
            "        -4.1396979e-02, -1.7794918e-02],\n",
            "       [-3.9817453e-03,  2.0466059e-02,  2.4437400e-02,  2.0180630e-04,\n",
            "         3.1026412e-02, -5.9210020e-03, -1.0918661e-02,  2.1861844e-02,\n",
            "        -6.9074653e-04,  3.0912677e-02],\n",
            "       [-5.0107244e-02,  2.9855186e-02,  9.5852930e-03,  1.6135816e-02,\n",
            "        -3.4944788e-02,  3.3194669e-02, -3.1547889e-02, -2.7411299e-02,\n",
            "         4.0137000e-02,  3.8704434e-03],\n",
            "       [ 2.2254294e-02,  2.1084962e-02,  5.0556981e-03, -4.1209415e-02,\n",
            "        -2.2030476e-02, -3.0688755e-02,  1.3587601e-02,  2.2694647e-02,\n",
            "        -2.9914500e-02, -2.6567215e-02],\n",
            "       [ 2.2286793e-02,  3.5006780e-02,  2.6568156e-02, -1.7439699e-02,\n",
            "        -2.3113234e-02,  1.1735797e-02,  5.3303260e-03, -1.0883530e-02,\n",
            "         1.5875617e-02, -1.3725651e-02],\n",
            "       [-9.3371021e-03, -4.0943973e-02,  8.4673176e-03, -4.7597121e-03,\n",
            "        -3.4061994e-02, -4.7303766e-02, -2.4440886e-02, -2.6865354e-02,\n",
            "         2.4338653e-02,  2.5531853e-02],\n",
            "       [ 1.3557028e-02, -1.8492030e-02, -2.1028668e-02,  3.6092248e-02,\n",
            "        -3.5436794e-03,  4.4470847e-02, -8.4811794e-03, -2.2147959e-02,\n",
            "         3.9275791e-02, -2.8973907e-02],\n",
            "       [ 3.3183441e-02, -4.7028404e-02, -2.7323205e-02,  3.3584606e-02,\n",
            "         1.8516675e-02, -4.2200010e-02,  7.4522775e-03,  4.6709474e-02,\n",
            "         2.8622700e-02, -2.6917228e-02]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7sWA55r9401",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8P062wBj0TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}