{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROBERTA_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4d960cf155b4eb0ac59a77dff735c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80010a24330c419bab7a83e1e75eea07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6bb39978746b4e2c98dc514956e4b5ac",
              "IPY_MODEL_0647090a7a7b4d7c8b348f2fdaa0e5ef"
            ]
          }
        },
        "80010a24330c419bab7a83e1e75eea07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bb39978746b4e2c98dc514956e4b5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1d688510fcf495c81882a09395b906f",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1df61caf0ab4cfb8487d67244d73942"
          }
        },
        "0647090a7a7b4d7c8b348f2fdaa0e5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26d5a7c1fac6473cb32c3d1de9fb3b97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [1:58:17&lt;00:00, 7097.61s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ab8c5870bf144d2bfb3fd6fcf8c965d"
          }
        },
        "b1d688510fcf495c81882a09395b906f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1df61caf0ab4cfb8487d67244d73942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26d5a7c1fac6473cb32c3d1de9fb3b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ab8c5870bf144d2bfb3fd6fcf8c965d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c0beebfec2443a2a1386acd69b7fef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64462b87095948c9832e80d5fd6fba7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ee8cb2406c34c679a4816de10c40251",
              "IPY_MODEL_e5fcf66e206f4b8d9ecf0b5f01c264df"
            ]
          }
        },
        "64462b87095948c9832e80d5fd6fba7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ee8cb2406c34c679a4816de10c40251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f5892e5f74743a3a93ea511b6f920e9",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48220,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48220,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8e6e008b6f748a6aea2336746dfea48"
          }
        },
        "e5fcf66e206f4b8d9ecf0b5f01c264df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ffe2a22ca5b242f0aae2fb39e32460f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48220/48220 [1:58:17&lt;00:00,  6.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d29a2cc283146e1967581aee7b9158b"
          }
        },
        "7f5892e5f74743a3a93ea511b6f920e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8e6e008b6f748a6aea2336746dfea48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffe2a22ca5b242f0aae2fb39e32460f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d29a2cc283146e1967581aee7b9158b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharani1999/Word-embedding-techniques/blob/master/ROBERTA_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53KR4rL_16LQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "2ba76abd-2154-46b9-e373-c2876d057310"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVIdyTbUk59U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3a9eb627-62da-4b3e-f561-666f8c9378db"
      },
      "source": [
        "import pickle\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "import time\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from gensim.parsing.preprocessing import stem_text\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "from gensim.models import Word2Vec, TfidfModel, LsiModel\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.python.framework import ops\n",
        "#tf.gfile = tf.io.gfile\n",
        "#tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "import random\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def save_object(obj, filename):\n",
        "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
        "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_object(filename):\n",
        "    with open(filename, 'rb') as input:\n",
        "        pickle_object = pickle.load(input)\n",
        "    return  pickle_object"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBxWRJOkYr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "faa9f471-2633-4660-8c7f-d10160b0d1d3"
      },
      "source": [
        "#!mkdir imdb\n",
        "\n",
        "def pre_process(data):\n",
        "  _sent=[]\n",
        "  for i in data:\n",
        "    sent = word_tokenize(i)\n",
        "    sent = [w.lower() for w in sent]\n",
        "    sent = [word for word in sent if word not in stop_words]\n",
        "    sent = [word for word in sent if word.isalpha()]\n",
        "    sent = [c for c in sent if not c.isdigit()]\n",
        "    #sent = [stem_text(w) for w in sent]\n",
        "    #sent = [wordnet_lemmatizer.lemmatize(w) for w in sent]\n",
        "    #sent = [word for word in sent if word not in stoplist]\n",
        "    _sent.append(sent)\n",
        "  return _sent\n",
        "\n",
        "from keras.datasets import imdb\n",
        "data = imdb.load_data(path='/content/drive/My Drive/Movielensdata/ml25m/imdb/data',\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3)\n",
        "save_object(data, '/content/drive/My Drive/Movielensdata/ml25m/imdb/data')\n",
        "word_to_idx_dict = imdb.get_word_index(path=\"/content/drive/My Drive/Movielensdata/ml25m/imdb/imdb_word_index.json\")\n",
        "n = len(word_to_idx_dict)\n",
        "print(\"Number distinct words in reviews = %d \\n\" % n)\n",
        "\n",
        "words_freq_list = []\n",
        "for (k,v) in word_to_idx_dict.items():\n",
        "  words_freq_list.append((k,v))\n",
        "\n",
        "sorted_list = sorted(words_freq_list, key=lambda x: x[1])\n",
        "\n",
        "print(\"Ten most common words: \\n\")\n",
        "print(sorted_list[0:10])\n",
        "\n",
        "print(\"\\nLast five least common words: \\n\")\n",
        "print(sorted_list[-5:])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 599dadb1135973df5b59232a0e9a887c so we will re-download the data.\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n",
            "Number distinct words in reviews = 88584 \n",
            "\n",
            "Ten most common words: \n",
            "\n",
            "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('br', 7), ('in', 8), ('it', 9), ('i', 10)]\n",
            "\n",
            "Last five least common words: \n",
            "\n",
            "[(\"pipe's\", 88580), ('copywrite', 88581), ('artbox', 88582), (\"voorhees'\", 88583), (\"'l'\", 88584)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXYcHjKSm7z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_module(reviews, name, location, output_location, dict_location, max_seq_length=100):\n",
        "  if reviews==False:\n",
        "    dataset1 = pd.read_csv(location)\n",
        "    dataset = dataset1.iloc[0:1000,:]\n",
        "  else:\n",
        "    dataset = load_object(location)\n",
        "  if name == 'word2vec':\n",
        "    data_corpus, users_total = data_word2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'doc2vec':\n",
        "    data_corpus, users_total = data_doc2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'lsi':\n",
        "    data_corpus, users_total = data_lsi(reviews,dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'tfidf':\n",
        "    data_corpus, users_total = data_lsi(reviews,dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'glove':\n",
        "    data_corpus, users_total = data_word2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'hashing':\n",
        "    data_corpus, users_total = data_hashing(reviews,dataset,max_seq_length)\n",
        "  elif name == 'cooccur':\n",
        "    data_corpus, users_total = data_hashing(reviews,dataset,max_seq_length)\n",
        "  #elif name == 'fasttext':\n",
        "   # data_corpus, users_total = data_word2vec(dataset,max_seq_length)\n",
        "  #data_corpus.save('/content/drive/My Drive/Movielensdata/ml25m/data_corpus')\n",
        "  #print(data_corpus)\n",
        "  save_object(obj=data_corpus, filename=output_location)\n",
        "  #return data_corpus, users_total\n",
        "\n",
        "def data_word2vec(review,dataset,max_seq_length):\n",
        "  if review==False:\n",
        "    dataset.sort_values(by=['userId','timestamp'],inplace=True)\n",
        "    user_total = len(dataset['userId'].unique())\n",
        "    \n",
        "    #Selecting the most recent movies rated by each user and padding if necessary\n",
        "    movie_list = []\n",
        "    for i in range(user_total):\n",
        "      list1 = []\n",
        "      list1 = dataset.loc[dataset['userId'] ==(i+1),['movieId']]['movieId'].tolist()\n",
        "      if len(list1)>max_seq_length:\n",
        "        list1 = list1[(len(list1)-max_seq_length):]\n",
        "      elif len(list1)<max_seq_length:\n",
        "        list1 = list1+[0 for j in range((max_seq_length-len(list1)))]\n",
        "        #for j in range((max_seq_length-len(list1))):\n",
        "        # list1.append(0)\n",
        "      movie_list.append(list1)\n",
        "\n",
        "    #Selecting the most recent ratings rated by each user and padding if necessary\n",
        "    rating_list =[]\n",
        "    for i in range(user_total):\n",
        "      list2 = []\n",
        "      list2 = dataset.loc[dataset['userId'] ==(i+1),['rating']]['rating'].tolist()\n",
        "      if len(list2)>max_seq_length:\n",
        "        list2 = list2[(len(list2)-max_seq_length):]\n",
        "      elif len(list2)<max_seq_length:\n",
        "        list2 = list2+[0 for j in range((max_seq_length-len(list2)))]\n",
        "        #for j in range((max_seq_length-len(list2))):\n",
        "        # list2.append(0)\n",
        "      rating_list.append(list2)\n",
        "\n",
        "    #Creating user_id level transpose matrices\n",
        "    movies_transpose = pd.DataFrame(data=movie_list,index=[i+1 for i in range(user_total)])\n",
        "    movies_transpose.index.names = ['userId']\n",
        "    #print(movies_transpose)\n",
        "\n",
        "    ratings_transpose = pd.DataFrame(data=rating_list,index=[i+1 for i in range(user_total)])\n",
        "    ratings_transpose.index.names = ['userId']\n",
        "    #print(ratings_transpose)\n",
        "\n",
        "    # Select features from original dataset to form a new dataframe \n",
        "    df1 = movies_transpose.iloc[:]# For each row, combine all the columns into one column\n",
        "    df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)# Store them in a pandas dataframe\n",
        "    df_clean = pd.DataFrame({'clean': df2})# Create the list of list format of the custom corpus for gensim modeling \n",
        "    sent = [row.split(',') for row in df_clean['clean']]\n",
        "\n",
        "    return sent, user_total\n",
        "  else:\n",
        "    X_train = dataset[0][0]\n",
        "    Y_train = dataset[0][1]\n",
        "    X_test, X_val, Y_test, Y_val = train_test_split(dataset[1][0], dataset[1][1], test_size=0.4, shuffle=False)\n",
        "    \n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_to_idx_dict.items()])\n",
        "    train_reviews=[]\n",
        "    for j in X_train:\n",
        "      train_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    test_reviews=[]\n",
        "    for j in X_test:\n",
        "      test_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    val_reviews=[]\n",
        "    for j in X_val:\n",
        "      val_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    train_sent=pre_process(train_reviews)\n",
        "    save_object(train_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent')\n",
        "    test_sent=pre_process(test_reviews)\n",
        "    save_object(test_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/test_sent')\n",
        "    val_sent=pre_process(val_reviews)\n",
        "    save_object(val_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/val_sent')\n",
        "    save_object(Y_train, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_train')\n",
        "    save_object(Y_test, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_test')\n",
        "    save_object(Y_val, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_val')\n",
        "\n",
        "    return train_sent, len(train_sent)\n",
        "\n",
        "def data_doc2vec(review,dataset,max_seq_length):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  tagged_data = []\n",
        "  tags = []\n",
        "  \n",
        "  for i in range(user_total):\n",
        "    tagged_data = tagged_data + [TaggedDocument(words=Sent[i], tags=[str(i)])]\n",
        "\n",
        "  return tagged_data, user_total\n",
        "\n",
        "def data_lsi(review,dataset,max_seq_length,dict_loc):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  dictionary = corpora.Dictionary(Sent)\n",
        "  #print(dictionary.token2id)\n",
        "  corpus = [dictionary.doc2bow(text) for text in Sent]\n",
        "  vocab = list(dictionary.values())\n",
        "  save_object(vocab,'/content/drive/My Drive/Movielensdata/ml25m/imdb/vocab') \n",
        "  dictionary.save(dict_loc)\n",
        "  print(dictionary)\n",
        "  #corpus = np.array([[(id, freq) for id, freq in cp] for cp in corp])\n",
        "  #corpus = gensim.matutils.Dense2Corpus(np.array(Sent),documents_columns=False)\n",
        "\n",
        "  return corpus, user_total\n",
        "\n",
        "def data_hashing(review,dataset,max_seq_length):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  corpus = [str(str(doc)[1:-1]) for doc in Sent]\n",
        "  return corpus, user_total"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnPTam8xlcWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "4858a6c2-8b69-4354-cf86-4942e4ae1035"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-cfgr10gf\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-cfgr10gf\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 27.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (1.12.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.16.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.0.2-cp36-none-any.whl size=793805 sha256=89ab370100b17ec396116941d4d08f940b2a4b8d5dad32ac79223eabcf08fc46\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xd167n8n/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f122250764f6cc9a93f8e3be04e5f715f359d0e234e42d0916b86fc5f49f0367\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.0.2\n",
            "tokenizers               0.8.1rc2       \n",
            "transformers             3.0.2          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oKUZOP9noqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_module(reviews=True, name='word2vec',max_seq_length=100,location='/content/drive/My Drive/Movielensdata/ml25m/imdb/data',output_location='/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent', dict_location='/content/drive/My Drive/Movielensdata/ml25m/imdb/dict/tfidf_dict')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SSvNLzPoTHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_vocab = load_object('/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uir0gd5ek0S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96540215-b2ab-4ee8-fc72-39f86e346935"
      },
      "source": [
        "print(len(bert_vocab))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzpgVBAdlLkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"train.txt\"\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for doc in bert_vocab:\n",
        "    for token in doc:\n",
        "      fo.write(token+\"\\n\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uIHHmNPlQd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "#paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "paths = '/content/train.txt'\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=1, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWTqw9Fl4A-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e8606cc-1ae4-4646-83b7-7bce421f4603"
      },
      "source": [
        "!mkdir BERT\n",
        "tokenizer.save_model(\"BERT\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BERT/vocab.json', 'BERT/merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R26thLQcl7RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer('/content/BERT/vocab.json', '/content/BERT/merges.txt')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unEFsRuvl7UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Ye27nchfzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b48e59a8-36db-406f-a6e2-06faf15883f8"
      },
      "source": [
        "#tokenizer.encode(\"'5952','2012','0'\")\n",
        "tokenizer.encode(\"name time place\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ya5_7rhjKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca21cede-05e5-413b-8058-778e6e28c152"
      },
      "source": [
        "tokenizer.encode(\"name time place\").tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'name', 'Ġ', 'time', 'Ġ', 'place', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWHb1ypTockQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "42594c76-e321-4861-b90c-ba6b64773d4a"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 21 15:57:39 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7RfOrt9mKGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f10c0035-1460-4b6b-a15d-83cbdca474a3"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMJ4IqtmKK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8RCpGhrmKO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./BERT\", max_len=512)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GcjP3QemiFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr5M3tFCmiCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc2e0207-4d33-4ffc-f822-0b97ee753a9e"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 84 million parameters"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84095008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT7MCkwtmmqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b803e107-3181-4847-9e17-e43dff33849c"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/train.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 2s, sys: 3.56 s, total: 1min 6s\n",
            "Wall time: 47.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqod29Wmmmnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-BrVMBlmh_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./BERT\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iop-zfOm9mC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "e4d960cf155b4eb0ac59a77dff735c7d",
            "80010a24330c419bab7a83e1e75eea07",
            "6bb39978746b4e2c98dc514956e4b5ac",
            "0647090a7a7b4d7c8b348f2fdaa0e5ef",
            "b1d688510fcf495c81882a09395b906f",
            "a1df61caf0ab4cfb8487d67244d73942",
            "26d5a7c1fac6473cb32c3d1de9fb3b97",
            "1ab8c5870bf144d2bfb3fd6fcf8c965d",
            "2c0beebfec2443a2a1386acd69b7fef5",
            "64462b87095948c9832e80d5fd6fba7f",
            "3ee8cb2406c34c679a4816de10c40251",
            "e5fcf66e206f4b8d9ecf0b5f01c264df",
            "7f5892e5f74743a3a93ea511b6f920e9",
            "c8e6e008b6f748a6aea2336746dfea48",
            "ffe2a22ca5b242f0aae2fb39e32460f8",
            "4d29a2cc283146e1967581aee7b9158b"
          ]
        },
        "outputId": "ef1c0d0f-2c9e-4e93-c054-03dbac4ed215"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4d960cf155b4eb0ac59a77dff735c7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0beebfec2443a2a1386acd69b7fef5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=48220.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=48220, training_loss=8.425708667335051)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB3XCYM0nDuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.save_model(\"./BERT\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltXgXyCbAJLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3ef73d2d-8bbf-42fa-9d96-6a37c1366985"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./BERT\",\n",
        "    tokenizer=\"./BERT\"\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:805: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIvgZ3S6AO0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#106916\n",
        "#fill_mask(\"this movie is <mask>\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ9HSQxAAbme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fill_mask(\"why <mask>\")\n",
        "#1265"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYtscxsW0RA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "683ab0bf-71ac-43f5-b5a2-0829f828f24a"
      },
      "source": [
        "sent = [\"this movie is nice\",\"didn't like it too boring\"]\n",
        "model.encode(sent)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c3834abadbe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"this movie is nice\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"didn't like it too boring\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RobertaForMaskedLM' object has no attribute 'encode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVIhLW5blu8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "8cf38b78-2195-4940-bc1b-667d73961601"
      },
      "source": [
        "sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fb5a5d13cfc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hidden_states' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWHo-ARXm7_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}