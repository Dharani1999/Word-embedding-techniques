{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roberta.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjS6Wb4KqVgdpqG2NVsHyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "367ea2f55d1d462bba41673809ce1be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c9c2ccc8d40460b86c7e17ccfe186c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_224636cbf2784c9c85cc7921389f5f5a",
              "IPY_MODEL_96a1d4ce73f74626aaa3ea601157a7dd"
            ]
          }
        },
        "0c9c2ccc8d40460b86c7e17ccfe186c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "224636cbf2784c9c85cc7921389f5f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29f4172b4f844f4d8e897568b52abb72",
            "_dom_classes": [],
            "description": "Epoch:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a1170238d26461d9dc9fdba18faa12c"
          }
        },
        "96a1d4ce73f74626aaa3ea601157a7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c582d3ac04e74f0aadb8ebcc705a1459",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2ccb281b4a94b23b284bf96f02cbc65"
          }
        },
        "29f4172b4f844f4d8e897568b52abb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a1170238d26461d9dc9fdba18faa12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c582d3ac04e74f0aadb8ebcc705a1459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2ccb281b4a94b23b284bf96f02cbc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4aad9e6a1a274c40a8ad0a1e5cb5a8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3da541189cce4122a251b085eb46c3d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bfb59b94e7664fff8aacd2ef7123f436",
              "IPY_MODEL_d75cc66f60974aa2906f580659ec7b7e"
            ]
          }
        },
        "3da541189cce4122a251b085eb46c3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfb59b94e7664fff8aacd2ef7123f436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5efc566248a4135927b6fb1852d0e4e",
            "_dom_classes": [],
            "description": "Iteration:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08c6c576c099415eaab873316c0cdd5e"
          }
        },
        "d75cc66f60974aa2906f580659ec7b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbf8bd6cc9c746dfbdb1f68f9ddb0f31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc8481b0c06b40689a9770d096982e9b"
          }
        },
        "b5efc566248a4135927b6fb1852d0e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08c6c576c099415eaab873316c0cdd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbf8bd6cc9c746dfbdb1f68f9ddb0f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc8481b0c06b40689a9770d096982e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharani1999/Word-embedding-techniques/blob/master/Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53KR4rL_16LQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ddb650c6-69c1-42aa-aa56-ce4fb32f583d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVIdyTbUk59U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "bee4efa8-4f72-45c4-8076-65773ff74749"
      },
      "source": [
        "import pickle\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "import time\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from gensim.parsing.preprocessing import stem_text\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "from gensim.models import Word2Vec, TfidfModel, LsiModel\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.python.framework import ops\n",
        "#tf.gfile = tf.io.gfile\n",
        "#tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "import random\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def save_object(obj, filename):\n",
        "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
        "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_object(filename):\n",
        "    with open(filename, 'rb') as input:\n",
        "        pickle_object = pickle.load(input)\n",
        "    return  pickle_object"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBxWRJOkYr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "c0b5832b-2b78-4d08-c4c6-0ac5d04d12f6"
      },
      "source": [
        "#!mkdir imdb\n",
        "\n",
        "def pre_process(data):\n",
        "  _sent=[]\n",
        "  for i in data:\n",
        "    sent = word_tokenize(i)\n",
        "    sent = [w.lower() for w in sent]\n",
        "    sent = [word for word in sent if word not in stop_words]\n",
        "    sent = [word for word in sent if word.isalpha()]\n",
        "    sent = [c for c in sent if not c.isdigit()]\n",
        "    #sent = [stem_text(w) for w in sent]\n",
        "    #sent = [wordnet_lemmatizer.lemmatize(w) for w in sent]\n",
        "    #sent = [word for word in sent if word not in stoplist]\n",
        "    _sent.append(sent)\n",
        "  return _sent\n",
        "\n",
        "from keras.datasets import imdb\n",
        "data = imdb.load_data(path='/content/drive/My Drive/Movielensdata/ml25m/imdb/data',\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3)\n",
        "save_object(data, '/content/drive/My Drive/Movielensdata/ml25m/imdb/data')\n",
        "word_to_idx_dict = imdb.get_word_index(path=\"/content/drive/My Drive/Movielensdata/ml25m/imdb/imdb_word_index.json\")\n",
        "n = len(word_to_idx_dict)\n",
        "print(\"Number distinct words in reviews = %d \\n\" % n)\n",
        "\n",
        "words_freq_list = []\n",
        "for (k,v) in word_to_idx_dict.items():\n",
        "  words_freq_list.append((k,v))\n",
        "\n",
        "sorted_list = sorted(words_freq_list, key=lambda x: x[1])\n",
        "\n",
        "print(\"Ten most common words: \\n\")\n",
        "print(sorted_list[0:10])\n",
        "\n",
        "print(\"\\nLast five least common words: \\n\")\n",
        "print(sorted_list[-5:])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 599dadb1135973df5b59232a0e9a887c so we will re-download the data.\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "Number distinct words in reviews = 88584 \n",
            "\n",
            "Ten most common words: \n",
            "\n",
            "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('br', 7), ('in', 8), ('it', 9), ('i', 10)]\n",
            "\n",
            "Last five least common words: \n",
            "\n",
            "[(\"pipe's\", 88580), ('copywrite', 88581), ('artbox', 88582), (\"voorhees'\", 88583), (\"'l'\", 88584)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXYcHjKSm7z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_module(reviews, name, location, output_location, dict_location, max_seq_length=100):\n",
        "  if reviews==False:\n",
        "    dataset1 = pd.read_csv(location)\n",
        "    dataset = dataset1.iloc[0:1000,:]\n",
        "  else:\n",
        "    dataset = load_object(location)\n",
        "  if name == 'word2vec':\n",
        "    data_corpus, users_total = data_word2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'doc2vec':\n",
        "    data_corpus, users_total = data_doc2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'lsi':\n",
        "    data_corpus, users_total = data_lsi(reviews,dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'tfidf':\n",
        "    data_corpus, users_total = data_lsi(reviews,dataset,max_seq_length,dict_loc=dict_location)\n",
        "  elif name == 'glove':\n",
        "    data_corpus, users_total = data_word2vec(reviews,dataset,max_seq_length)\n",
        "  elif name == 'hashing':\n",
        "    data_corpus, users_total = data_hashing(reviews,dataset,max_seq_length)\n",
        "  elif name == 'cooccur':\n",
        "    data_corpus, users_total = data_hashing(reviews,dataset,max_seq_length)\n",
        "  #elif name == 'fasttext':\n",
        "   # data_corpus, users_total = data_word2vec(dataset,max_seq_length)\n",
        "  #data_corpus.save('/content/drive/My Drive/Movielensdata/ml25m/data_corpus')\n",
        "  #print(data_corpus)\n",
        "  save_object(obj=data_corpus, filename=output_location)\n",
        "  #return data_corpus, users_total\n",
        "\n",
        "def data_word2vec(review,dataset,max_seq_length):\n",
        "  if review==False:\n",
        "    dataset.sort_values(by=['userId','timestamp'],inplace=True)\n",
        "    user_total = len(dataset['userId'].unique())\n",
        "    \n",
        "    #Selecting the most recent movies rated by each user and padding if necessary\n",
        "    movie_list = []\n",
        "    for i in range(user_total):\n",
        "      list1 = []\n",
        "      list1 = dataset.loc[dataset['userId'] ==(i+1),['movieId']]['movieId'].tolist()\n",
        "      if len(list1)>max_seq_length:\n",
        "        list1 = list1[(len(list1)-max_seq_length):]\n",
        "      elif len(list1)<max_seq_length:\n",
        "        list1 = list1+[0 for j in range((max_seq_length-len(list1)))]\n",
        "        #for j in range((max_seq_length-len(list1))):\n",
        "        # list1.append(0)\n",
        "      movie_list.append(list1)\n",
        "\n",
        "    #Selecting the most recent ratings rated by each user and padding if necessary\n",
        "    rating_list =[]\n",
        "    for i in range(user_total):\n",
        "      list2 = []\n",
        "      list2 = dataset.loc[dataset['userId'] ==(i+1),['rating']]['rating'].tolist()\n",
        "      if len(list2)>max_seq_length:\n",
        "        list2 = list2[(len(list2)-max_seq_length):]\n",
        "      elif len(list2)<max_seq_length:\n",
        "        list2 = list2+[0 for j in range((max_seq_length-len(list2)))]\n",
        "        #for j in range((max_seq_length-len(list2))):\n",
        "        # list2.append(0)\n",
        "      rating_list.append(list2)\n",
        "\n",
        "    #Creating user_id level transpose matrices\n",
        "    movies_transpose = pd.DataFrame(data=movie_list,index=[i+1 for i in range(user_total)])\n",
        "    movies_transpose.index.names = ['userId']\n",
        "    #print(movies_transpose)\n",
        "\n",
        "    ratings_transpose = pd.DataFrame(data=rating_list,index=[i+1 for i in range(user_total)])\n",
        "    ratings_transpose.index.names = ['userId']\n",
        "    #print(ratings_transpose)\n",
        "\n",
        "    # Select features from original dataset to form a new dataframe \n",
        "    df1 = movies_transpose.iloc[:]# For each row, combine all the columns into one column\n",
        "    df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)# Store them in a pandas dataframe\n",
        "    df_clean = pd.DataFrame({'clean': df2})# Create the list of list format of the custom corpus for gensim modeling \n",
        "    sent = [row.split(',') for row in df_clean['clean']]\n",
        "\n",
        "    return sent, user_total\n",
        "  else:\n",
        "    X_train = dataset[0][0]\n",
        "    Y_train = dataset[0][1]\n",
        "    X_test, X_val, Y_test, Y_val = train_test_split(dataset[1][0], dataset[1][1], test_size=0.4, shuffle=False)\n",
        "    \n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_to_idx_dict.items()])\n",
        "    train_reviews=[]\n",
        "    for j in X_train:\n",
        "      train_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    test_reviews=[]\n",
        "    for j in X_test:\n",
        "      test_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    val_reviews=[]\n",
        "    for j in X_val:\n",
        "      val_reviews.append(' '.join([reverse_word_index.get(i - 3, '') for i in j]))\n",
        "\n",
        "    train_sent=pre_process(train_reviews)\n",
        "    save_object(train_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent')\n",
        "    test_sent=pre_process(test_reviews)\n",
        "    save_object(test_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/test_sent')\n",
        "    val_sent=pre_process(val_reviews)\n",
        "    save_object(val_sent,'/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/val_sent')\n",
        "    save_object(Y_train, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_train')\n",
        "    save_object(Y_test, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_test')\n",
        "    save_object(Y_val, '/content/drive/My Drive/Movielensdata/ml25m/imdb/Y/Y_val')\n",
        "\n",
        "    return train_sent, len(train_sent)\n",
        "\n",
        "def data_doc2vec(review,dataset,max_seq_length):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  tagged_data = []\n",
        "  tags = []\n",
        "  \n",
        "  for i in range(user_total):\n",
        "    tagged_data = tagged_data + [TaggedDocument(words=Sent[i], tags=[str(i)])]\n",
        "\n",
        "  return tagged_data, user_total\n",
        "\n",
        "def data_lsi(review,dataset,max_seq_length,dict_loc):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  dictionary = corpora.Dictionary(Sent)\n",
        "  #print(dictionary.token2id)\n",
        "  corpus = [dictionary.doc2bow(text) for text in Sent]\n",
        "  vocab = list(dictionary.values())\n",
        "  save_object(vocab,'/content/drive/My Drive/Movielensdata/ml25m/imdb/vocab') \n",
        "  dictionary.save(dict_loc)\n",
        "  print(dictionary)\n",
        "  #corpus = np.array([[(id, freq) for id, freq in cp] for cp in corp])\n",
        "  #corpus = gensim.matutils.Dense2Corpus(np.array(Sent),documents_columns=False)\n",
        "\n",
        "  return corpus, user_total\n",
        "\n",
        "def data_hashing(review,dataset,max_seq_length):\n",
        "  Sent, user_total = data_word2vec(review,dataset,max_seq_length)\n",
        "  corpus = [str(str(doc)[1:-1]) for doc in Sent]\n",
        "  return corpus, user_total"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnPTam8xlcWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "be6a1829-0c03-484f-fd3c-b72a36bb0a18"
      },
      "source": [
        "#tokenizer working version --- 0.5.0\n",
        "#transformer working version --- 2.5.0\n",
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install tensorboard==2.1.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-lnx48o1i\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-lnx48o1i\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.16.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.0.2-cp36-none-any.whl size=795716 sha256=467b4eb7d6f2d6938eae4bdd88ba8b9e36553e9133173108684437ca0431dd92\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bqnq117l/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4249f5cbb0363ce79e6a5fd8e90baf0b8f856d819eaa62a387cf5ca5bb9ff720\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.0.2\n",
            "tokenizers               0.8.1rc2       \n",
            "transformers             3.0.2          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oKUZOP9noqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_module(reviews=True, name='word2vec',max_seq_length=100,location='/content/drive/My Drive/Movielensdata/ml25m/imdb/data',output_location='/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent', dict_location='/content/drive/My Drive/Movielensdata/ml25m/imdb/dict/tfidf_dict')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SSvNLzPoTHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = load_object('/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/train_sent')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uir0gd5ek0S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f6e6fd0-0408-4d48-aa2d-cf1ca871c5fb"
      },
      "source": [
        "print(len(train_text))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q79xM9b9i0Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_text = load_object('/content/drive/My Drive/Movielensdata/ml25m/imdb/processed_data/test_sent')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLYbwtRNi0F6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84d2dc70-54e7-409b-f87e-e7528ed38791"
      },
      "source": [
        "print(len(eval_text))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzpgVBAdlLkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"train.txt\"\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for doc in train_text[0:100]:\n",
        "    for token in doc:\n",
        "      fo.write(token+' ')\n",
        "    fo.write('\\n')\n",
        "    fo.write('\\n')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yog2MbJTivfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"eval.txt\"\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for doc in eval_text[0:100]:\n",
        "    for token in doc:\n",
        "      fo.write(token+' ')\n",
        "    fo.write('\\n')\n",
        "    fo.write('\\n')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uIHHmNPlQd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "#paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "paths = '/content/train.txt'\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=1, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWTqw9Fl4A-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d667f18d-12af-49f6-bd81-08aa43aed4fb"
      },
      "source": [
        "!mkdir BERT\n",
        "tokenizer.save_model(\"BERT\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BERT/vocab.json', 'BERT/merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R26thLQcl7RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer('/content/BERT/vocab.json', '/content/BERT/merges.txt')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unEFsRuvl7UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Ye27nchfzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90dea671-e1a9-4d10-e80e-efad5fccc227"
      },
      "source": [
        "#tokenizer.encode(\"'5952','2012','0'\")\n",
        "tokenizer.encode(\"name time place\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ya5_7rhjKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "392089a5-3068-4e80-82ed-e76d13af1023"
      },
      "source": [
        "tokenizer.encode(\"name time place\").tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'n', 'ame', 'Ġtime', 'Ġplace', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWHb1ypTockQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "5752833e-0168-4826-8e96-2eecd1f2c07f"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 23 20:47:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7RfOrt9mKGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "868eb8ee-2401-4c84-ad6e-d0aedf2267ae"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMJ4IqtmKK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8RCpGhrmKO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./BERT\", max_len=512)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GcjP3QemiFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaModel\n",
        "\n",
        "model = RobertaModel(config=config)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAPgSs_7qF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "addbfac7-878a-427f-e60d-d665fe7b33f6"
      },
      "source": [
        "model.get_input_embeddings()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(52000, 768, padding_idx=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr5M3tFCmiCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5cfc41a-04b2-48df-9aa9-10210b0b11f1"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 84 million parameters"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84043010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSGzhz1VfCNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_pretrained('/content/BERT/model')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT7MCkwtmmqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23f4ca18-1055-4e82-89f4-f71918c282c0"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/train.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 67.5 ms, sys: 1.07 ms, total: 68.5 ms\n",
            "Wall time: 42.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDc8-116-ZbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_collator = DataCollatorForLanguageModeling(\n",
        " #   tokenizer=tokenizer, mlm=False, mlm_probability=0.15\n",
        "#)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-BrVMBlmh_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./BERT\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iop-zfOm9mC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "367ea2f55d1d462bba41673809ce1be2",
            "0c9c2ccc8d40460b86c7e17ccfe186c5",
            "224636cbf2784c9c85cc7921389f5f5a",
            "96a1d4ce73f74626aaa3ea601157a7dd",
            "29f4172b4f844f4d8e897568b52abb72",
            "8a1170238d26461d9dc9fdba18faa12c",
            "c582d3ac04e74f0aadb8ebcc705a1459",
            "e2ccb281b4a94b23b284bf96f02cbc65",
            "4aad9e6a1a274c40a8ad0a1e5cb5a8fd",
            "3da541189cce4122a251b085eb46c3d5",
            "bfb59b94e7664fff8aacd2ef7123f436",
            "d75cc66f60974aa2906f580659ec7b7e",
            "b5efc566248a4135927b6fb1852d0e4e",
            "08c6c576c099415eaab873316c0cdd5e",
            "cbf8bd6cc9c746dfbdb1f68f9ddb0f31",
            "cc8481b0c06b40689a9770d096982e9b"
          ]
        },
        "outputId": "7597dfcc-4e96-4227-aea6-78dcd9914d2a"
      },
      "source": [
        "trainer.train(model_path='./BERT')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "367ea2f55d1d462bba41673809ce1be2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aad9e6a1a274c40a8ad0a1e5cb5a8fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0379c698b723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./BERT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 if (step + 1) % self.args.gradient_accumulation_steps == 0 or (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, optimizer)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_tuple)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You have to specify either input_ids or inputs_embeds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB3XCYM0nDuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.save_model(\"./BERT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYtscxsW0RA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = [\"this movie is nice\",\"didn't like it too boring\"]\n",
        "model.encode(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVIhLW5blu8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}